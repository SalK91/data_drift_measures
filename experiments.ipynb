{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy.stats\n",
    "from scipy.stats import ks_2samp, entropy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate numeric distribution\n",
    "def generate_distribution(size=100000, seed=1000):\n",
    "    np.random.seed(seed)\n",
    "    distribution1 = np.random.normal(loc=-3, scale=1, size=int(size * 0.2))\n",
    "    distribution2 = np.random.normal(loc=2, scale=0.5, size=int(size * 0.2))\n",
    "    distribution3 = np.random.normal(loc=5, scale=2, size=int(size * 0.2))\n",
    "    distribution4 = np.random.exponential(scale=1, size=int(size * 0.2))\n",
    "    distribution5 = np.random.uniform(low=-1, high=1, size=int(size * 0.2))\n",
    "    return np.concatenate([distribution1, distribution2, distribution3, distribution4, distribution5])\n",
    "\n",
    "\n",
    "def introduce_drift(original_distribution, drift_magnitude=0.0, frame=0, total_frames=5, undersamplefactor=1):\n",
    "    # Simulate dynamic shift in means of normal distributions over frames\n",
    "    mean_shift = drift_magnitude #* np.sin(2 * np.pi * frame / total_frames)\n",
    "    distribution1 = np.random.normal(loc=-3 + mean_shift, scale=1, size=int(len(original_distribution) * 0.2)//undersamplefactor)\n",
    "    distribution2 = np.random.normal(loc=2 + mean_shift, scale=0.5, size=int(len(original_distribution) * 0.2)//undersamplefactor)\n",
    "    distribution3 = np.random.normal(loc=5 + mean_shift, scale=2, size=int(len(original_distribution) * 0.2)//undersamplefactor)\n",
    "    distribution4 = np.random.exponential(scale=1, size=int(len(original_distribution) * 0.2)//undersamplefactor)\n",
    "    distribution5 = np.random.uniform(low=-1, high=1, size=int(len(original_distribution) * 0.2)//undersamplefactor)\n",
    "\n",
    "    return np.concatenate([distribution1, distribution2, distribution3, distribution4, distribution5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make pdf from samples\n",
    "def probabilty_distribtion_from_samples(actual, expected, buckets=20 , epsilon=1e-11):\n",
    "    \n",
    "    # Cap data at 1st and 99th percentiles\n",
    "    expected = np.clip(expected, np.percentile(expected, 1), np.percentile(expected, 99))\n",
    "    actual = np.clip(actual, np.percentile(actual, 1), np.percentile(actual, 99))\n",
    "\n",
    "    # Create bins for the variable\n",
    "    bins = np.linspace(min(expected.min(), actual.min()), max(expected.max(), actual.max()), buckets + 1)\n",
    "\n",
    "    # Discretize the variable into bins\n",
    "    expected_bins = pd.cut(expected, bins, include_lowest=True)\n",
    "    actual_bins = pd.cut(actual, bins, include_lowest=True)\n",
    "\n",
    "    # Convert Categorical columns to Series\n",
    "    expected_labels = expected_bins.astype(str)\n",
    "    actual_labels = actual_bins.astype(str)\n",
    "\n",
    "  \n",
    "    # Find common labels using NumPy's intersect1d\n",
    "    common_labels = np.intersect1d(np.unique(expected_labels), np.unique(actual_labels))\n",
    "\n",
    "    if len(np.unique(expected_labels)) != len(np.unique(common_labels)):\n",
    "        print(\"Warning: Expected labels do not match common labels\")\n",
    "        return probabilty_distribtion_from_samples(expected, actual, buckets=int(buckets/2), epsilon=1e-11)\n",
    "    \n",
    "    if len(np.unique(common_labels)) != len(np.unique(actual_labels)):\n",
    "        print(\"Warning: Expected labels do not match common labels\")\n",
    "        actual_proportions,expected_proportions = probabilty_distribtion_from_samples(expected, actual, buckets=int(buckets/2), epsilon=1e-9)\n",
    "        return probabilty_distribtion_from_samples(expected, actual, buckets=int(buckets/2), epsilon=1e-11)\n",
    "    \n",
    "    # Perform boolean indexing to get common bins\n",
    "    expected_common = expected_bins[np.isin(expected_labels, common_labels)]\n",
    "    actual_common = actual_bins[np.isin(actual_labels, common_labels)]\n",
    "\n",
    "    # Calculate the proportion of observations in each bin for both datasets\n",
    "    expected_proportions = (expected_common.value_counts().sort_index() + epsilon) / (len(expected_common) + epsilon*len(np.unique(common_labels)))\n",
    "    actual_proportions = (actual_common.value_counts().sort_index() + epsilon) / (len(actual_common) + epsilon*len(np.unique(common_labels)))\n",
    "\n",
    " \n",
    "    return actual_proportions,expected_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute PSI\n",
    "def calculate_psi(expected, actual, buckets=10, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) for a variable.\n",
    "\n",
    "    Parameters:\n",
    "        expected (array-like): Expected values (e.g., training dataset).\n",
    "        actual (array-like): Actual values (e.g., test dataset).\n",
    "        buckets (int): Number of bins for discretizing the variable.\n",
    "        epsilon (float): Small constant to add to expected proportions.\n",
    "\n",
    "    Returns:\n",
    "        float: Population Stability Index (PSI).\n",
    "    \"\"\"\n",
    "\n",
    "    actual_proportions, expected_proportions =  probabilty_distribtion_from_samples(actual, expected, buckets=buckets , epsilon=1e-9)\n",
    "    \n",
    "    # Calculate the PSI for each bin\n",
    "    psi_values = (actual_proportions - expected_proportions) * np.log(actual_proportions / expected_proportions)\n",
    "\n",
    "    # Sum the PSI values to get the overall PSI\n",
    "    psi = psi_values.sum()\n",
    "\n",
    "    return psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute metrics\n",
    "def compute_metrics(reference_distribution_samples, variant_distribution_samples):\n",
    "    # Two-sample mean z-test\n",
    "    z_test, p_value = scipy.stats.ttest_ind(reference_distribution_samples, variant_distribution_samples)\n",
    "\n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_statistic, ks_p_value = ks_2samp(reference_distribution_samples, variant_distribution_samples)\n",
    "\n",
    "    # Convert Samples to Probability Distributions\n",
    "    ref_pdf, variant_pdf = probabilty_distribtion_from_samples(reference_distribution_samples, variant_distribution_samples)\n",
    "    \n",
    "    \n",
    "    # KL Divergence\n",
    "    kl_divergence = np.sum(variant_pdf * np.log(variant_pdf / ref_pdf))\n",
    "\n",
    "\n",
    "    # JS Distance\n",
    "    js_distance = distance.jensenshannon(ref_pdf, variant_pdf)\n",
    "\n",
    "    # PSI Index\n",
    "    psi_index = calculate_psi(reference_distribution_samples, variant_distribution_samples)\n",
    "\n",
    "\n",
    "    # K-Sample Anderson-Darling\n",
    "    result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n",
    "\n",
    "\n",
    "    return z_test, p_value, ks_statistic, ks_p_value, kl_divergence, js_distance, psi_index, result.significance_level\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value capped: true value larger than 0.25\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Expected labels do not match common labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salmank\\AppData\\Local\\Temp\\ipykernel_12904\\905130667.py:25: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = anderson_ksamp([reference_distribution_samples, variant_distribution_samples])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drift Type</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>T Test (p-value)</th>\n",
       "      <th>KS (p-value)</th>\n",
       "      <th>AK (p-value)</th>\n",
       "      <th>KL Divergence</th>\n",
       "      <th>JS Distance</th>\n",
       "      <th>PSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.198091e-47</td>\n",
       "      <td>1.106136e-101</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.168074</td>\n",
       "      <td>0.193463</td>\n",
       "      <td>0.310323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>25000</td>\n",
       "      <td>6.716136e-127</td>\n",
       "      <td>9.176624e-249</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.178625</td>\n",
       "      <td>0.200113</td>\n",
       "      <td>0.333151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>50000</td>\n",
       "      <td>1.301025e-234</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.166433</td>\n",
       "      <td>0.193757</td>\n",
       "      <td>0.311386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.169606</td>\n",
       "      <td>0.194859</td>\n",
       "      <td>0.315302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>250000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.175437</td>\n",
       "      <td>0.198560</td>\n",
       "      <td>0.327580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>500000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.173565</td>\n",
       "      <td>0.197542</td>\n",
       "      <td>0.324029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Large Drift</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.175112</td>\n",
       "      <td>0.198365</td>\n",
       "      <td>0.326861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>10000</td>\n",
       "      <td>9.063946e-01</td>\n",
       "      <td>8.127749e-01</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>25000</td>\n",
       "      <td>1.117020e-01</td>\n",
       "      <td>1.503627e-01</td>\n",
       "      <td>0.117579</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.001048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>50000</td>\n",
       "      <td>1.633783e-01</td>\n",
       "      <td>7.480849e-02</td>\n",
       "      <td>0.040037</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>100000</td>\n",
       "      <td>1.566995e-02</td>\n",
       "      <td>9.405624e-04</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>250000</td>\n",
       "      <td>3.326824e-04</td>\n",
       "      <td>1.514712e-09</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>500000</td>\n",
       "      <td>2.541321e-10</td>\n",
       "      <td>5.310250e-20</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Negligible Drift</td>\n",
       "      <td>1000000</td>\n",
       "      <td>3.887067e-14</td>\n",
       "      <td>1.446032e-39</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Drift Type  Sample Size  T Test (p-value)   KS (p-value)  \\\n",
       "0        Large Drift        10000      1.198091e-47  1.106136e-101   \n",
       "1        Large Drift        25000     6.716136e-127  9.176624e-249   \n",
       "2        Large Drift        50000     1.301025e-234   0.000000e+00   \n",
       "3        Large Drift       100000      0.000000e+00   0.000000e+00   \n",
       "4        Large Drift       250000      0.000000e+00   0.000000e+00   \n",
       "5        Large Drift       500000      0.000000e+00   0.000000e+00   \n",
       "6        Large Drift      1000000      0.000000e+00   0.000000e+00   \n",
       "7   Negligible Drift        10000      9.063946e-01   8.127749e-01   \n",
       "8   Negligible Drift        25000      1.117020e-01   1.503627e-01   \n",
       "9   Negligible Drift        50000      1.633783e-01   7.480849e-02   \n",
       "10  Negligible Drift       100000      1.566995e-02   9.405624e-04   \n",
       "11  Negligible Drift       250000      3.326824e-04   1.514712e-09   \n",
       "12  Negligible Drift       500000      2.541321e-10   5.310250e-20   \n",
       "13  Negligible Drift      1000000      3.887067e-14   1.446032e-39   \n",
       "\n",
       "    AK (p-value)  KL Divergence  JS Distance       PSI  \n",
       "0       0.001000       0.168074     0.193463  0.310323  \n",
       "1       0.001000       0.178625     0.200113  0.333151  \n",
       "2       0.001000       0.166433     0.193757  0.311386  \n",
       "3       0.001000       0.169606     0.194859  0.315302  \n",
       "4       0.001000       0.175437     0.198560  0.327580  \n",
       "5       0.001000       0.173565     0.197542  0.324029  \n",
       "6       0.001000       0.175112     0.198365  0.326861  \n",
       "7       0.250000       0.000955     0.015412  0.001131  \n",
       "8       0.117579       0.000929     0.015256  0.001048  \n",
       "9       0.040037       0.001155     0.016983  0.001554  \n",
       "10      0.005343       0.000634     0.012578  0.000688  \n",
       "11      0.001000       0.000628     0.012541  0.000945  \n",
       "12      0.001000       0.000769     0.013872  0.001089  \n",
       "13      0.001000       0.000658     0.012833  0.001011  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters\n",
    "sample_sizes = [10000, 25000, 50000, 100000, 250000, 500000, 1000000]\n",
    "drift_magnitude_small = 0.05\n",
    "drift_magnitude_drastic = 1.0\n",
    "\n",
    "\n",
    "# CREATE empty dataframe to store all metrics\n",
    "metric_values = pd.DataFrame(columns=['Drift Type','Sample Size', 'T Test (p-value)',  'KS (p-value)',  'AK (p-value)', 'KL Divergence', 'JS Distance', 'PSI'])\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(i)\n",
    "# Function to update the plots for each frame\n",
    "    for sample_size in sample_sizes:\n",
    "        #print(sample_size)\n",
    "        reference_distribution = generate_distribution(size=sample_size)\n",
    "        variant_distribution_small_drift = introduce_drift(reference_distribution, drift_magnitude_small)\n",
    "        variant_distribution_drastic_drift = introduce_drift(reference_distribution, drift_magnitude_drastic)\n",
    "\n",
    "        z_test_small_drift, p_value_small_drift, ks_statistic_small_drift, ks_p_value_small_drift, kl_divergence_small_drift, js_distance_small_drift, psi_index_small_drift , anderson_ksamp_small= compute_metrics(reference_distribution, variant_distribution_small_drift)\n",
    "        z_test_drastic_drift, p_value_drastic_drift, ks_statistic_drastic_drift, ks_p_value_drastic_drift, kl_divergence_drastic_drift, js_distance_drastic_drift, psi_index_drastic_drift , anderson_ksamp_drastic= compute_metrics(reference_distribution, variant_distribution_drastic_drift)\n",
    "\n",
    "        small = pd.DataFrame({'Drift Type':'Negligible Drift', 'Sample Size':sample_size,  \n",
    "                              'T Test (p-value)':p_value_small_drift, 'KS (p-value)':ks_p_value_small_drift, 'AK (p-value)':anderson_ksamp_small,\n",
    "                              'KL Divergence':kl_divergence_small_drift, \n",
    "                              'JS Distance':js_distance_small_drift, 'PSI':psi_index_small_drift}, index=[0])\n",
    "        metric_values = pd.concat([metric_values,small], ignore_index=True)\n",
    "        \n",
    "        drastic = pd.DataFrame({'Drift Type':'Large Drift', 'Sample Size':sample_size, \n",
    "                                'T Test (p-value)':p_value_drastic_drift,  'KS (p-value)':ks_p_value_drastic_drift,  'AK (p-value)':anderson_ksamp_drastic,\n",
    "                                'KL Divergence':kl_divergence_drastic_drift, 'JS Distance':js_distance_drastic_drift, 'PSI':psi_index_drastic_drift}, index=[0])\n",
    "        metric_values = pd.concat([metric_values,drastic], ignore_index=True)\n",
    "\n",
    "# group by drift type and sample size and compute all means and don't forget to reset the index\n",
    "metric_values = metric_values.groupby(['Drift Type','Sample Size']).mean().reset_index()\n",
    "metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# order by typ descending\n",
    "metric_values = metric_values.sort_values(by=['Drift Type'], ascending=False)\n",
    "\n",
    "# reindex dataframe\n",
    "metric_values = metric_values.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# save to excel\n",
    "metric_values.to_csv('metrics.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
